seed_everything: true
trainer:
  accelerator: gpu
  strategy: ddp_find_unused_parameters_true
  devices: 1
  num_nodes: 1
  precision: 16-mixed
  max_epochs: 50
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 0
  log_every_n_steps: 100
  callbacks:
    - class_path: lightning.pytorch.callbacks.ModelCheckpoint
      init_args:
        dirpath: "vq_log/simvq_1k" # Please specify your own path
        save_top_k: -1 # save all checkpoints
    - class_path: lightning.pytorch.callbacks.LearningRateMonitor
      init_args:
        logging_interval: step
  logger:
    class_path: lightning.pytorch.loggers.TensorBoardLogger
    init_args:
      save_dir: "vq_log/simvq_1k" #Please specify your own path
      version: "size128"
      name:

model:
  class_path: taming.models.vq.VQModel
  init_args:
    ddconfig:
      double_z: False
      z_channels: 128
      resolution: 128
      in_channels: 3
      out_ch: 3
      ch: 128
      ch_mult: [1,2,2,4]  # num_down = len(ch_mult)-1
      num_res_blocks: 2

    quantconfig:
      target: taming.modules.vqvae.quantize.SimVQ
      params:
        n_e: 1024
        e_dim: 128
        beta: 0.25
        legacy: false

    lossconfig:
      target: taming.modules.losses.vqperceptual.VQLPIPSWithDiscriminator
      params:
        disc_conditional: False
        disc_in_channels: 3
        disc_start: 0 # from 0 epoch
        gen_loss_weight: 0.1
        commit_weight: 1.0

    learning_rate: 1e-4
    scheduler_type: "None"
    use_ema: True

data:
  class_path: main.DataModuleFromConfig
  init_args:
    batch_size: 64
    num_workers: 8
    train:
      target: taming.data.imagenet.ImageNetTrain
      params:
        config:
          size: 128
          subset:
    validation:
      target: taming.data.imagenet.ImageNetValidation
      params:
        config:
          size: 128
          subset:
    test:
      target: taming.data.imagenet.ImageNetValidation
      params:
        config:
          size: 128
          subset:

ckpt_path: null # to resume